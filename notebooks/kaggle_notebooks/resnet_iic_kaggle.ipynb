{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: this notebook is designed to be run on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import matplotlib.pyplot as plot\n",
    "from image_utils import label_images, plot_images, count_samples\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import Model, Sequential, models, layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "np.random.seed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verify if tensorflow is running with GPU\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "# # check if keras is using GPU\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data, sample size, and image parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# define datasets\n",
    "train_data_dir = \"/kaggle/input/intel-image-classification/seg_train/seg_train/\"\n",
    "test_data_dir = \"/kaggle/input/intel-image-classification/seg_test/seg_test/\"\n",
    "pred_dir = \"/kaggle/input/intel-image-classification/seg_pred/seg_pred/\"\n",
    " \n",
    "# define datasets and sample size\n",
    "num_train_samples = count_samples(train_data_dir)\n",
    "num_test_samples = count_samples(test_data_dir)\n",
    "\n",
    "# define image dimensions\n",
    "img_width, img_height = 150, 150\n",
    "img_target_size = (img_width, img_height)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_imgs, labeled_training_imgs = label_images(train_data_dir, '.jpg')\n",
    "# plot_images(training_imgs, labeled_training_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters and data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "neurons_per_layer = [128, 64]\n",
    "dropout = 0.25\n",
    "n_classes = 6\n",
    "patience = 3\n",
    "\n",
    "# specify image augmentation\n",
    "img_augmentation = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "      rotation_range=90,\n",
    "      horizontal_flip=True,\n",
    "      vertical_flip=True)\n",
    "\n",
    "# prepare train/test data generators\n",
    "train_data = img_augmentation.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = img_target_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "test_data = img_augmentation.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size = img_target_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify base model and freeze weights\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# create model function\n",
    "def create_model(base_model, dropout, neurons_per_layer, num_classes):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    for num_neurons in neurons_per_layer:\n",
    "        x = layers.Dense(num_neurons, activation='relu')(x) \n",
    "    \n",
    "    x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    classifications = layers.Dense(num_classes, activation='softmax')(x) \n",
    "    model = Model(inputs=base_model.input, outputs=classifications)\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# instantiate model\n",
    "model = create_model(base_model, dropout=dropout, neurons_per_layer=neurons_per_layer, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=patience)]\n",
    "\n",
    "# train model\n",
    "history = model.fit_generator(\n",
    "    train_data,\n",
    "    steps_per_epoch = num_train_samples // batch_size,\n",
    "    validation_data = test_data,\n",
    "    validation_steps = num_test_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    verbose = 1,\n",
    "    use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training vs val accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot(history.history['acc'])\n",
    "plot.plot(history.history['val_acc'])\n",
    "plot.title('Model accuracy')\n",
    "plot.ylabel('Accuracy')\n",
    "plot.xlabel('Epoch')\n",
    "plot.legend(['Train', 'Test'], loc='upper left')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = model.evaluate_generator(test_data,\n",
    "    steps = num_test_samples // batch_size,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True)\n",
    "\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
